{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": " Script Assignment 1: Spam Classifier",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Before we start, we import some preliminary libraries.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Import necessary libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# Load the SpamAssassin dataset using pandas\nspam_df = pd.read_csv('spam_dataset.csv')\n\n# Explore the dataset\nprint(spam_df.head())\n\n# Handle missing values if any\nspam_df.dropna(inplace=True)\n\n\n\n# Split the data into features (X) and target variable (y)\nX = spam_df['text']\ny = spam_df['target']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Text vectorization using CountVectorizer\nvectorizer = CountVectorizer()\nX_train_vec = vectorizer.fit_transform(X_train)\nX_test_vec = vectorizer.transform(X_test)\n\n# Linear Regression Classifier\nlinear_classifier = LogisticRegression(max_iter=1000)\nlinear_classifier.fit(X_train_vec, y_train)\nlinear_predictions = linear_classifier.predict(X_test_vec)\n\n# Decision Tree Classifier\ntree_classifier = DecisionTreeClassifier()\ntree_classifier.fit(X_train_vec, y_train)\ntree_predictions = tree_classifier.predict(X_test_vec)\n\n# Random Forest Classifier\nforest_classifier = RandomForestClassifier()\nforest_classifier.fit(X_train_vec, y_train)\nforest_predictions = forest_classifier.predict(X_test_vec)\n\n# Evaluate the models\ndef evaluate_model(y_true, y_pred, classifier_name):\n    print(f\"Classification Report for {classifier_name}:\")\n    print(classification_report(y_true, y_pred))\n    print(f\"Confusion Matrix for {classifier_name}:\")\n    print(confusion_matrix(y_true, y_pred))\n    print(f\"Accuracy Score for {classifier_name}: {accuracy_score(y_true, y_pred)}\")\n    print(\"\\n\")\n\n# Evaluate each classifier\nevaluate_model(y_test, linear_predictions, \"Linear Regression\")\nevaluate_model(y_test, tree_predictions, \"Decision Tree\")\nevaluate_model(y_test, forest_predictions, \"Random Forest\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                                                text  target\n0  From ilug-admin@linux.ie Mon Jul 29 11:28:02 2...       0\n1  From gort44@excite.com Mon Jun 24 17:54:21 200...       1\n2  From fork-admin@xent.com Mon Jul 29 11:39:57 2...       1\n3  From dcm123@btamail.net.cn Mon Jun 24 17:49:23...       1\n4  From ilug-admin@linux.ie Mon Aug 19 11:02:47 2...       0\nClassification Report for Linear Regression:\n              precision    recall  f1-score   support\n\n           0       0.99      1.00      1.00       779\n           1       1.00      0.99      0.99       381\n\n    accuracy                           1.00      1160\n   macro avg       1.00      0.99      1.00      1160\nweighted avg       1.00      1.00      1.00      1160\n\nConfusion Matrix for Linear Regression:\n[[778   1]\n [  4 377]]\nAccuracy Score for Linear Regression: 0.9956896551724138\n\n\nClassification Report for Decision Tree:\n              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99       779\n           1       0.98      0.98      0.98       381\n\n    accuracy                           0.99      1160\n   macro avg       0.98      0.98      0.98      1160\nweighted avg       0.99      0.99      0.99      1160\n\nConfusion Matrix for Decision Tree:\n[[771   8]\n [  8 373]]\nAccuracy Score for Decision Tree: 0.9862068965517241\n\n\nClassification Report for Random Forest:\n              precision    recall  f1-score   support\n\n           0       0.99      1.00      0.99       779\n           1       1.00      0.98      0.99       381\n\n    accuracy                           0.99      1160\n   macro avg       0.99      0.99      0.99      1160\nweighted avg       0.99      0.99      0.99      1160\n\nConfusion Matrix for Random Forest:\n[[779   0]\n [  9 372]]\nAccuracy Score for Random Forest: 0.9922413793103448\n\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": " Script Assignment 2: Handwritten Digits Classifier",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Import necessary libraries\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import metrics\n\n# Load the MNIST dataset\ndigits = datasets.load_digits()\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2, random_state=42)\n\n# K-nearest Neighbors (KNN) classifier\nknn_classifier = KNeighborsClassifier()\nknn_classifier.fit(X_train, y_train)\n\n# Support Vector Machines (SVM) classifier\nsvm_classifier = SVC()\nsvm_classifier.fit(X_train, y_train)\n\n# Naive Bayes classifier\nnb_classifier = GaussianNB()\nnb_classifier.fit(X_train, y_train)\n\n# Evaluate the models\nknn_predictions = knn_classifier.predict(X_test)\nsvm_predictions = svm_classifier.predict(X_test)\nnb_predictions = nb_classifier.predict(X_test)\n\n# Print performance metrics\nprint(\"KNN Accuracy:\", metrics.accuracy_score(y_test, knn_predictions))\nprint(\"SVM Accuracy:\", metrics.accuracy_score(y_test, svm_predictions))\nprint(\"Naive Bayes Accuracy:\", metrics.accuracy_score(y_test, nb_predictions))",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/lib/python3.11/site-packages/threadpoolctl.py:1019: RuntimeWarning: libc not found. The ctypes module in Python 3.11 is maybe too old for this OS.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "KNN Accuracy: 0.9861111111111112\nSVM Accuracy: 0.9861111111111112\nNaive Bayes Accuracy: 0.8472222222222222\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 1
    }
  ]
}